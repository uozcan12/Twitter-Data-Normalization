# Twitter-Data-Normalization

## Softwares

* NLTK
* Python 2.7

## Sample Dataset

* http://www.kemik.yildiz.edu.tr/data/File/2milyon_tweet.rar

## Projects Steps

* Analyzing the dataset and finding general mistakes when users send
tweets
* To tokenize with NLTK
* Analyzing the words and

1. correction accent marks
2. correction extra whitespaces
3. omitting unnecessary letters in words
4. adding the forgotten letters in words
5. identify emojis
6. identify mentions
7. identify hashtags
8. identify punctuations
9. identify symbols

* Testing results
