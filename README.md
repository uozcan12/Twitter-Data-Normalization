# Twitter-Data-Normalization

## Softwares

* Python 3.4

## Sample Dataset

* http://www.kemik.yildiz.edu.tr/data/File/2milyon_tweet.rar

## Projects Steps

* Analyzing the dataset and finding general mistakes when users send
tweets :white_check_mark:
* To tokenize with NLTK :white_check_mark:
* Analyzing the words and

1. identified and correct emphasize words :white_check_mark:
2. adding the forgotten letters in words :white_check_mark:
3. correct Turkish sms words :white_check_mark:
4. identify emojis :white_check_mark:
5. identify mentions :white_check_mark:
6. identify hashtags :white_check_mark:
7. identify urls :white_check_mark:
8. identify punctions :white_check_mark:
9. identify symbols :white_check_mark:
10. correction accent marks :white_check_mark:
11. correction extra whitespaces :white_check_mark:
12. making deascifiier :white_check_mark:

* Testing results :white_check_mark:
